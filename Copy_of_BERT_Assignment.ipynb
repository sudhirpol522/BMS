{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gWFtHVfRM40O",
    "outputId": "9b6e7c72-5eb3-4668-90c0-6c9b88b0963e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5el_8SqFqVAT"
   },
   "source": [
    "\n",
    "In this notebook, You will do amazon review classification with BERT.[Download data from [this](https://www.kaggle.com/snap/amazon-fine-food-reviews/data) link]\n",
    "<pre> \n",
    "It contains 5 parts as below.  Detailed instrctions are given in the each cell. please read every comment we have written. \n",
    "    1. Preprocessing \n",
    "    2. Creating a BERT model from the Tensorflow HUB.\n",
    "    3. Tokenization\n",
    "    4. getting the pretrained embedding Vector for a given review from the BERT.\n",
    "    5. Using the embedding data apply NN and classify the reviews.\n",
    "    6. Creating a Data pipeline for BERT Model. \n",
    "\n",
    "<font size=5>instructions:</font>\n",
    "\n",
    "    1. Don't change any Grader Functions. Don't manipulate any Grader functions. \n",
    "    If you manipulate any, it will be considered as plagiarised. \n",
    "    \n",
    "    2. Please read the instructions on the code cells and markdown cells. We will explain what to write. \n",
    "    \n",
    "    3. please return outputs in the same format what we asked. Eg. Don't return List if we are asking for a numpy array.\n",
    "    \n",
    "    4. Please read the external links that we are given so that you will learn the concept behind the code that you are writing.\n",
    "    \n",
    "    5. We are giving instructions at each section if necessary, please follow them. \n",
    "\n",
    "<font size=5>Every Grader function has to return True. </font>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wOtG4cf0qVAZ"
   },
   "outputs": [],
   "source": [
    "#all imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "OcmiHdAJqVAi",
    "outputId": "2d9f9344-29bd-4874-aad0-49d7568a6425"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 237,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LBsay58AqVAo"
   },
   "source": [
    "<font size=4>Grader function 1 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aTBvOKFeqVAq",
    "outputId": "e86960b4-465b-4f4f-bcef-02e964bb4c80"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 238,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_tf_version():\n",
    "    assert((tf.__version__)>'2')\n",
    "    return True\n",
    "grader_tf_version()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZTWRqbrBqVAu"
   },
   "source": [
    "<pre><font size=6>Part-1: Preprocessing</font></pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B3csZKDrqVAv",
    "outputId": "251006f4-0282-4a65-9690-a0ce4a8617f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 568454 entries, 0 to 568453\n",
      "Data columns (total 10 columns):\n",
      " #   Column                  Non-Null Count   Dtype \n",
      "---  ------                  --------------   ----- \n",
      " 0   Id                      568454 non-null  int64 \n",
      " 1   ProductId               568454 non-null  object\n",
      " 2   UserId                  568454 non-null  object\n",
      " 3   ProfileName             568438 non-null  object\n",
      " 4   HelpfulnessNumerator    568454 non-null  int64 \n",
      " 5   HelpfulnessDenominator  568454 non-null  int64 \n",
      " 6   Score                   568454 non-null  int64 \n",
      " 7   Time                    568454 non-null  int64 \n",
      " 8   Summary                 568427 non-null  object\n",
      " 9   Text                    568454 non-null  object\n",
      "dtypes: int64(5), object(5)\n",
      "memory usage: 43.4+ MB\n"
     ]
    }
   ],
   "source": [
    "#Read the dataset - Amazon fine food reviews\n",
    "reviews = pd.read_csv(r\"/content/drive/MyDrive/NLP Transfer Learning/Reviews.csv\")\n",
    "#check the info of the dataset\n",
    "reviews.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xokNn7qZqVAz"
   },
   "outputs": [],
   "source": [
    "#get only 2 columns - Text, Score\n",
    "#drop the NAN values\n",
    "reviews=reviews[['Text','Score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "XbHdAcL7NqsY",
    "outputId": "ac6c6a27-de5e-49e3-dd6e-34d4958af93e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Score\n",
       "0  I have bought several of the Vitality canned d...      5\n",
       "1  Product arrived labeled as Jumbo Salted Peanut...      1\n",
       "2  This is a confection that has been around a fe...      4\n",
       "3  If you are looking for the secret ingredient i...      2\n",
       "4  Great taffy at a great price.  There was a wid...      5"
      ]
     },
     "execution_count": 241,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gk5nnRQtN00v",
    "outputId": "e534749b-1ec5-4ca4-d0c8-e7cd9feace70"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(568454, 2)"
      ]
     },
     "execution_count": 242,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5GZt7pVkqVA4"
   },
   "outputs": [],
   "source": [
    "#if score> 3, set score = 1\n",
    "#if score<=2, set score = 0\n",
    "#if score == 3, remove the rows. \n",
    "w=[]\n",
    "l=[]\n",
    "for i,j in zip(reviews['Text'],reviews['Score']):\n",
    "  if j>3:\n",
    "    w.append(i)\n",
    "    l.append(1)\n",
    "  if j<=2:\n",
    "    w.append(i)\n",
    "    l.append(0)\n",
    "  else:\n",
    "    continue\n",
    "\n",
    "\n",
    "\n",
    "##reviews['Score']=reviews['Score'].apply(lambda x: 0 if x<=2)\n",
    "\n",
    "##reviews['Score']=reviews['Score'].apply(lambda x: continue if x==3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xz3THxsTUis9"
   },
   "outputs": [],
   "source": [
    "reviews=pd.DataFrame()\n",
    "reviews['Text']=w\n",
    "reviews['Score']=l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A6xngzuQU1p6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oVe8LlkrqVA6"
   },
   "source": [
    "<font size=4>Grader function 2 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7mDXSiJpqVA7",
    "outputId": "07ca8813-1769-4ae2-cc4c-4d12ae80a8a3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 245,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_reviews():\n",
    "    temp_shape = (reviews.shape == (525814, 2)) and (reviews.Score.value_counts()[1]==443777)\n",
    "    assert(temp_shape == True)\n",
    "    return True\n",
    "grader_reviews()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xYZ-UB9UqVA-"
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_wordlen(x):\n",
    "    return len(x.split())\n",
    "reviews['len'] = reviews.Text.apply(get_wordlen)\n",
    "reviews = reviews[reviews.len<50]\n",
    "reviews = reviews.sample(n=100000, random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "17FTuxF7VJrV"
   },
   "outputs": [],
   "source": [
    "def html(x):\n",
    "  soup = BeautifulSoup(x)\n",
    "  return soup.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CvldQriGqVBB"
   },
   "outputs": [],
   "source": [
    "#remove HTML from the Text column and save in the Text column only\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "reviews['Text']=reviews['Text'].apply(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "AhfN1s2mqVBD",
    "outputId": "c90cbdcf-2130-441c-e9c8-a7e09d0f9fdd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Score</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59023</th>\n",
       "      <td>The tea was of great quality and it tasted lik...</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386645</th>\n",
       "      <td>My cat loves this.  The pellets are nice and s...</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330655</th>\n",
       "      <td>Great product. Does not completely get rid of ...</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162217</th>\n",
       "      <td>This gum is my favorite!  I would advise every...</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164797</th>\n",
       "      <td>I also found out about this product because of...</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Text  Score  len\n",
       "59023   The tea was of great quality and it tasted lik...      1   30\n",
       "386645  My cat loves this.  The pellets are nice and s...      1   31\n",
       "330655  Great product. Does not completely get rid of ...      1   41\n",
       "162217  This gum is my favorite!  I would advise every...      1   27\n",
       "164797  I also found out about this product because of...      1   22"
      ]
     },
     "execution_count": 249,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print head 5\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NsYDd3okqVBF"
   },
   "outputs": [],
   "source": [
    "#split the data into train and test data(20%) with Stratify sampling, random state 33, \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(reviews['Text'], reviews['Score'], test_size=0.2, random_state=33,stratify= reviews['Score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "-Q6OAcrOqVBI",
    "outputId": "400359bf-7974-443d-d6ea-11762670ad6d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f5f637daf60>"
      ]
     },
     "execution_count": 251,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot bar graphs of y_train and y_test\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.barplot(x=y_train.value_counts().index, y=y_train.value_counts())\n",
    "#plt.show()\n",
    "#y_train.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Up-z5boWqVBK"
   },
   "outputs": [],
   "source": [
    "#saving to disk. if we need, we can load preprocessed data directly. \n",
    "reviews.to_csv('preprocessed.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bBtqNGN9qVBM"
   },
   "source": [
    "<pre><font size=6>Part-2: Creating BERT Model</font> \n",
    "\n",
    "If you want to know more about BERT, You can watch live sessions on Transformers and BERt. \n",
    "we will strongly recommend you to read <a href=\"https://jalammar.github.io/illustrated-transformer/\">Transformers</a>, <a href=\"https://arxiv.org/abs/1810.04805\">BERT Paper</a> and, <a href=\"https://jalammar.github.io/a-visual-guide-to-using-bert-for-the-first-time/\">This blog</a>.\n",
    "\n",
    "\n",
    "For this assignment, we are using <a href=\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\">BERT uncased Base model</a>. \n",
    "It uses L=12 hidden layers (i.e., Transformer blocks), a hidden size of H=768, and A=12 attention heads. </pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i8xd2HejqVBN"
   },
   "outputs": [],
   "source": [
    "## Loading the Pretrained Model from tensorflow HUB\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# maximum length of a seq in the data we have, for now i am making it as 55. You can change this\n",
    "max_seq_length = 55\n",
    "\n",
    "#BERT takes 3 inputs\n",
    "\n",
    "#this is input words. Sequence of words represented as integers\n",
    "input_word_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name=\"input_word_ids\")\n",
    "\n",
    "#mask vector if you are padding anything\n",
    "input_mask = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name=\"input_mask\")\n",
    "\n",
    "#segment vectors. If you are giving only one sentence for the classification, total seg vector is 0. \n",
    "#If you are giving two sentenced with [sep] token separated, first seq segment vectors are zeros and \n",
    "#second seq segment vector are 1's\n",
    "segment_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name=\"segment_ids\")\n",
    "\n",
    "#bert layer \n",
    "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\", trainable=False)\n",
    "pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n",
    "\n",
    "#Bert model\n",
    "#We are using only pooled output not sequence out. \n",
    "#If you want to know about those, please read https://www.kaggle.com/questions-and-answers/86510\n",
    "bert_model = Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=pooled_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lQJsjg6fqVBQ",
    "outputId": "5d6400b3-42d8-4339-ebc6-c9ba7a195971"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_word_ids (InputLayer)     [(None, 55)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_mask (InputLayer)         [(None, 55)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segment_ids (InputLayer)        [(None, 55)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "keras_layer (KerasLayer)        [(None, 768), (None, 109482241   input_word_ids[0][0]             \n",
      "                                                                 input_mask[0][0]                 \n",
      "                                                                 segment_ids[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 109,482,241\n",
      "Trainable params: 0\n",
      "Non-trainable params: 109,482,241\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "bert_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w3z0OMA5qVBS",
    "outputId": "8492ea71-3bc8-4216-bdff-a41e8223db6b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 768) dtype=float32 (created by layer 'keras_layer')>"
      ]
     },
     "execution_count": 255,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model.output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ewv4hFCsqVBU"
   },
   "source": [
    "<pre><font size=6>Part-3: Tokenization</font></pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tX3VEFjiqVBU"
   },
   "outputs": [],
   "source": [
    "#getting Vocab file\n",
    "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dvoHDIYOogne",
    "outputId": "f9909ca6-19b4-468c-89ae-62e281dc1535"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (0.1.94)\n"
     ]
    }
   ],
   "source": [
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Alh2awQ8nAVA"
   },
   "outputs": [],
   "source": [
    "from tokenization import FullTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y_iPwa99qVBW"
   },
   "outputs": [],
   "source": [
    "#import tokenization - We have given tokenization.py file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "guJMLJ8bqVBY"
   },
   "outputs": [],
   "source": [
    "# Create tokenizer \" Instantiate FullTokenizer\" \n",
    "# name must be \"tokenizer\"\n",
    "# the FullTokenizer takes two parameters 1. vocab_file and 2. do_lower_case \n",
    "# we have created these in the above cell ex: FullTokenizer(vocab_file, do_lower_case )\n",
    "# please check the \"tokenization.py\" file the complete implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xD3aQ98yo5up"
   },
   "outputs": [],
   "source": [
    "tokenizer=FullTokenizer(vocab_file,do_lower_case )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e6S6HouSo-OS",
    "outputId": "cc386580-1dbd-40da-f0b5-4fbd1783b1dc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tokenization.FullTokenizer at 0x7f5f6db24860>"
      ]
     },
     "execution_count": 262,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KKkGLhR-qVBd"
   },
   "source": [
    "<font size=4>Grader function 3 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2CPu850xqVBe",
    "outputId": "6048db20-597a-446a-efc7-fe576ed90528"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 263,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#it has to give no error \n",
    "def grader_tokenize(tokenizer):\n",
    "    out = False\n",
    "    try:\n",
    "        out=('[CLS]' in tokenizer.vocab) and ('[SEP]' in tokenizer.vocab)\n",
    "    except:\n",
    "        out = False\n",
    "    assert(out==True)\n",
    "    return out\n",
    "grader_tokenize(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9crhPylQqVBg"
   },
   "outputs": [],
   "source": [
    "# Create train and test tokens (X_train_tokens, X_test_tokens) from (X_train, X_test) using Tokenizer and \n",
    "\n",
    "# add '[CLS]' at start of the Tokens and '[SEP]' at the end of the tokens. \n",
    "\n",
    "# maximum number of tokens is 55(We already given this to BERT layer above) so shape is (None, 55)\n",
    "\n",
    "# if it is less than 55, add '[PAD]' token else truncate the tokens length.(similar to padding)\n",
    "\n",
    "# Based on padding, create the mask for Train and Test ( 1 for real token, 0 for '[PAD]'), \n",
    "# it will also same shape as input tokens (None, 55) save those in X_train_mask, X_test_mask\n",
    "\n",
    "# Create a segment input for train and test. We are using only one sentence so all zeros. This shape will also (None, 55)\n",
    "\n",
    "# type of all the above arrays should be numpy arrays\n",
    "\n",
    "# after execution of this cell, you have to get \n",
    "# X_train_tokens, X_train_mask, X_train_segment\n",
    "# X_test_tokens, X_test_mask, X_test_segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e2M1XEOSvbNu",
    "outputId": "e729e6de-f6cf-44ea-c0db-a6985b28c6da"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30767     I had never tried this brand before, so I was ...\n",
       "9931      I love these for a snack. I get a nice taste o...\n",
       "360927    This is my favorite store bought cookie. Crumb...\n",
       "49637     I must be spoiled because this coffee was very...\n",
       "432498    the tins are much smaller than I expected.  bu...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 265,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MP5n4pc6yDdJ"
   },
   "source": [
    "##For X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PHLVQolFpXYU"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "q=[]\n",
    "y_train_=[]\n",
    "X_train_tokens=[]\n",
    "#X_train_mask=np.array([])\n",
    "for i in range(X_train.shape[0]):\n",
    "  try:\n",
    "    tokens=tokenizer.tokenize(X_train[i])\n",
    "  except:\n",
    "    continue\n",
    "  \n",
    "  tokens=tokens[:(max_seq_length-2)]\n",
    "  tokens=['[CLS]',*tokens,'[SEP]']\n",
    "  temp_length=len(tokens)\n",
    "  temp_X_train_tokens=tokenizer.convert_tokens_to_ids(tokens)\n",
    "  y_train_.append(y_train[i])\n",
    "  #print(temp_X_train_tokens)\n",
    "  X_train_tokens.append(temp_X_train_tokens)\n",
    "  temp_length=len(temp_X_train_tokens)\n",
    "  #print(tf.keras.preprocessing.sequence.pad_sequences(temp_X_train_tokens, maxlen=max_seq_length,padding='post'))\n",
    " # np.append(X_train_tokens,tf.keras.preprocessing.sequence.pad_sequences(temp_X_train_tokens, maxlen=max_seq_length,padding='post'),axis=0)\n",
    "  q.append(([1]*temp_length) + ([0]*(max_seq_length-temp_length)))\n",
    "  #X_train_mask=np.append(X_train_mask,np.array([1]*temp_length +[0]*(max_seq_length-temp_length)))\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zp29qtpPwe40",
    "outputId": "c4ed281c-1fe4-4845-b884-fdb5b6fbc982"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11868, 55)"
      ]
     },
     "execution_count": 267,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_mask=np.array(q)\n",
    "X_train_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f0jVGIrMxc96"
   },
   "outputs": [],
   "source": [
    "X_train_tokens=tf.keras.preprocessing.sequence.pad_sequences(X_train_tokens, maxlen=max_seq_length,padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QufpN2rZHS0d"
   },
   "outputs": [],
   "source": [
    "X_train_segment=np.zeros_like(X_train_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9nFbWfqRHrpK",
    "outputId": "ed8017df-168c-4029-b7c2-b7f943b0cf05"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11868, 55)"
      ]
     },
     "execution_count": 270,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_segment.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DqFtNvsDTj5v",
    "outputId": "eb1e808b-3d52-42c2-ff37-bc67ff2cd31e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 69603, 0: 10397})\n",
      "Counter({1: 17401, 0: 2599})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(Counter(y_train))\n",
    "print(Counter(y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AJL3hiJOyK7x"
   },
   "source": [
    "##For X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B-Tt_6G9HzNn"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "q=[]\n",
    "X_test_tokens=[]\n",
    "y_test_=[]\n",
    "#X_train_mask=np.array([])\n",
    "for i in range(X_test.shape[0]):\n",
    "  try:\n",
    "    tokens=tokenizer.tokenize(X_test[i])\n",
    "  except:\n",
    "    continue\n",
    "  y_test_.append(y_test[i])\n",
    "  \n",
    "  tokens=tokens[:(max_seq_length-2)]\n",
    "  tokens=['[CLS]',*tokens,'[SEP]']\n",
    "  temp_length=len(tokens)\n",
    "  temp_X_train_tokens=tokenizer.convert_tokens_to_ids(tokens)\n",
    "  #print(temp_X_train_tokens)\n",
    "  X_test_tokens.append(temp_X_train_tokens)\n",
    "  temp_length=len(temp_X_train_tokens)\n",
    "  #print(tf.keras.preprocessing.sequence.pad_sequences(temp_X_train_tokens, maxlen=max_seq_length,padding='post'))\n",
    " # np.append(X_train_tokens,tf.keras.preprocessing.sequence.pad_sequences(temp_X_train_tokens, maxlen=max_seq_length,padding='post'),axis=0)\n",
    "  q.append(([1]*temp_length) + ([0]*(max_seq_length-temp_length)))\n",
    "  #X_train_mask=np.append(X_train_mask,np.array([1]*temp_length +[0]*(max_seq_length-temp_length)))\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z4M_f-xMJ1cY",
    "outputId": "fd404680-3519-4ffc-9599-fb664a0beda8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(796, 55)"
      ]
     },
     "execution_count": 273,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_mask=np.array(q)\n",
    "X_test_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9sJSif60J6O4"
   },
   "outputs": [],
   "source": [
    "X_test_tokens=tf.keras.preprocessing.sequence.pad_sequences(X_test_tokens, maxlen=max_seq_length,padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V-Ps18yIJ-TQ"
   },
   "outputs": [],
   "source": [
    "X_test_segment=np.zeros_like(X_test_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EXIrTdYeKB7m"
   },
   "outputs": [],
   "source": [
    "y_train=np.array(y_train_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DmTSYKNAL91o"
   },
   "outputs": [],
   "source": [
    "y_test=np.array(y_test_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kv1-t4OjqVBj"
   },
   "source": [
    "#### Example\n",
    "<img src='https://i.imgur.com/5AhhmgU.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dxhggBxwqVBj"
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xF0idMRDqVBm"
   },
   "outputs": [],
   "source": [
    "##save all your results to disk so that, no need to run all again. \n",
    "pickle.dump((X_train, X_train_tokens, X_train_mask, X_train_segment, y_train),open('train_data.pkl','wb'))\n",
    "pickle.dump((X_test, X_test_tokens, X_test_mask, X_test_segment, y_test),open('test_data.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Leu1URGzqVBo"
   },
   "outputs": [],
   "source": [
    "#you can load from disk\n",
    "#X_train, X_train_tokens, X_train_mask, X_train_segment, y_train = pickle.load(open(\"train_data.pkl\", 'rb')) \n",
    "#X_test, X_test_tokens, X_test_mask, X_test_segment, y_test = pickle.load(open(\"test_data.pkl\", 'rb')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sjPv8VkJqVBr"
   },
   "source": [
    "<font size=4>Grader function 4 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qekHJgmdqVBs",
    "outputId": "9edc39a9-26be-4731-87c7-8bc5aaf4aec0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 281,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_alltokens_train():\n",
    "    out = False\n",
    "    \n",
    "    if type(X_train_tokens) == np.ndarray:\n",
    "        \n",
    "        temp_shapes = (X_train_tokens.shape[1]==max_seq_length) and (X_train_mask.shape[1]==max_seq_length) and \\\n",
    "        (X_train_segment.shape[1]==max_seq_length)\n",
    "        \n",
    "        segment_temp = not np.any(X_train_segment)\n",
    "        \n",
    "        mask_temp = np.sum(X_train_mask==0) == np.sum(X_train_tokens==0)\n",
    "        \n",
    "        no_cls = np.sum(X_train_tokens==tokenizer.vocab['[CLS]'])==X_train_tokens.shape[0]\n",
    "        \n",
    "        no_sep = np.sum(X_train_tokens==tokenizer.vocab['[SEP]'])==X_train_tokens.shape[0]\n",
    "        \n",
    "        out = temp_shapes and segment_temp and mask_temp and no_cls and no_sep\n",
    "      \n",
    "    else:\n",
    "        print('Type of all above token arrays should be numpy array not list')\n",
    "        out = False\n",
    "    assert(out==True)\n",
    "    return out\n",
    "\n",
    "grader_alltokens_train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KnvC6X_wqVBu"
   },
   "source": [
    "<font size=4>Grader function 5 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Av4SRMPSqVBv",
    "outputId": "07ba1600-7ecf-4685-bb90-912ac41e8729"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 282,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_alltokens_test():\n",
    "    out = False\n",
    "    if type(X_test_tokens) == np.ndarray:\n",
    "        \n",
    "        temp_shapes = (X_test_tokens.shape[1]==max_seq_length) and (X_test_mask.shape[1]==max_seq_length) and \\\n",
    "        (X_test_segment.shape[1]==max_seq_length)\n",
    "        \n",
    "        segment_temp = not np.any(X_test_segment)\n",
    "        \n",
    "        mask_temp = np.sum(X_test_mask==0) == np.sum(X_test_tokens==0)\n",
    "        \n",
    "        no_cls = np.sum(X_test_tokens==tokenizer.vocab['[CLS]'])==X_test_tokens.shape[0]\n",
    "        \n",
    "        no_sep = np.sum(X_test_tokens==tokenizer.vocab['[SEP]'])==X_test_tokens.shape[0]\n",
    "        \n",
    "        out = temp_shapes and segment_temp and mask_temp and no_cls and no_sep\n",
    "      \n",
    "    else:\n",
    "        print('Type of all above token arrays should be numpy array not list')\n",
    "        out = False\n",
    "    assert(out==True)\n",
    "    return out\n",
    "grader_alltokens_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SEj-Eua5qVBx"
   },
   "source": [
    "<pre><font size=6>Part-4: Getting Embeddings from BERT Model</font>\n",
    "We already created the BERT model in the part-2 and input data in the part-3. \n",
    "We will utlize those two and will get the embeddings for each sentence in the \n",
    "Train and test data.</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QwOVgQFDqVBy",
    "outputId": "c0b278c8-6bcd-41eb-bd4e-8e36ab6a7522"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor: shape=(None, 55) dtype=int32 (created by layer 'input_word_ids')>,\n",
       " <KerasTensor: shape=(None, 55) dtype=int32 (created by layer 'input_mask')>,\n",
       " <KerasTensor: shape=(None, 55) dtype=int32 (created by layer 'segment_ids')>]"
      ]
     },
     "execution_count": 283,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZcpkQq1OqVB0",
    "outputId": "0ec4f025-c836-4653-e538-8e86d3131863"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 768) dtype=float32 (created by layer 'keras_layer')>"
      ]
     },
     "execution_count": 284,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IxdIlOIBlm7j"
   },
   "outputs": [],
   "source": [
    "# get the train output, BERT model will give one output so save in\n",
    "# X_train_pooled_output\n",
    "X_train_pooled_output=bert_model.predict([X_train_tokens,X_train_mask,X_train_segment])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-xI5_gKELjHf",
    "outputId": "78d0f48a-84df-4766-ebea-b27531bff0d8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11868, 768)"
      ]
     },
     "execution_count": 286,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pooled_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yZT11BCol4gL"
   },
   "outputs": [],
   "source": [
    "# get the test output, BERT model will give one output so save in\n",
    "# X_test_pooled_output\n",
    "X_test_pooled_output=bert_model.predict([X_test_tokens,X_test_mask,X_test_segment])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uwpia-23Lw7p",
    "outputId": "6ad90178-ff60-4821-be95-231cb741e3ce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(796, 768)"
      ]
     },
     "execution_count": 288,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_pooled_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DL6JVojfqVB8"
   },
   "outputs": [],
   "source": [
    "##save all your results to disk so that, no need to run all again. \n",
    "pickle.dump((X_train_pooled_output, X_test_pooled_output),open('final_output.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oSQcBdROqVB9"
   },
   "outputs": [],
   "source": [
    "#X_train_pooled_output, X_test_pooled_output= pickle.load(open('final_output.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ulEXFE7aqVCA"
   },
   "source": [
    "<font size=4>Grader function 6 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oHCsW0IvqVCB",
    "outputId": "58204c1f-323d-4ded-8314-b54307695b0d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 291,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now we have X_train_pooled_output, y_train\n",
    "#X_test_pooled_ouput, y_test\n",
    "\n",
    "#please use this grader to evaluate\n",
    "def greader_output():\n",
    "    assert(X_train_pooled_output.shape[1]==768)\n",
    "    assert(len(y_train)==len(X_train_pooled_output))\n",
    "    assert(X_test_pooled_output.shape[1]==768)\n",
    "    assert(len(y_test)==len(X_test_pooled_output))\n",
    "    assert(len(y_train.shape)==1)\n",
    "    assert(len(X_train_pooled_output.shape)==2)\n",
    "    assert(len(y_test.shape)==1)\n",
    "    assert(len(X_test_pooled_output.shape)==2)\n",
    "    return True\n",
    "greader_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oYwS1QbAqVCD"
   },
   "source": [
    "<pre><font size=6>Part-5: Training a NN with 768 features</font>\n",
    "\n",
    "Create a NN and train the NN. \n",
    "1.<b> You have to use AUC as metric.</b> \n",
    "2. You can use any architecture you want. \n",
    "3. You have to use tensorboard to log all your metrics and Losses. You have to send those logs. \n",
    "4. Print the loss and metric at every epoch. \n",
    "5. You have to submit without overfitting and underfitting. \n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "od8PQlYRqVCE"
   },
   "outputs": [],
   "source": [
    "##imports\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, Dropout\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ALXoJiivM8ap"
   },
   "outputs": [],
   "source": [
    "Y_train = tf.keras.utils.to_categorical(y_train) \n",
    "Y_test = tf.keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mBDiiOpf2K5z"
   },
   "outputs": [],
   "source": [
    "def auc1(y_true, y_pred):\n",
    "    if len(np.unique(y_true[:,1])) == 1:\n",
    "        return 0.5\n",
    "    else:\n",
    "        return roc_auc_score(y_true, y_pred)\n",
    "\n",
    "def auroc(y_true, y_pred):\n",
    "    return tf.py_function(auc1, (y_true, y_pred), tf.double)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DSnmX3WnqVCG",
    "outputId": "c7e5b3aa-a7a2-4b46-ae7c-1b5b44b5a52f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "742/742 [==============================] - 9s 9ms/step - loss: 0.5885 - auc_4: 0.7700 - val_loss: 0.3654 - val_auc_4: 0.8991\n",
      "Epoch 2/10\n",
      "742/742 [==============================] - 6s 8ms/step - loss: 0.4158 - auc_4: 0.8632 - val_loss: 0.3926 - val_auc_4: 0.8677\n",
      "Epoch 3/10\n",
      "742/742 [==============================] - 6s 8ms/step - loss: 0.4023 - auc_4: 0.8713 - val_loss: 0.3708 - val_auc_4: 0.8744\n",
      "Epoch 4/10\n",
      "742/742 [==============================] - 6s 8ms/step - loss: 0.3994 - auc_4: 0.8669 - val_loss: 0.3595 - val_auc_4: 0.9016\n",
      "Epoch 5/10\n",
      "742/742 [==============================] - 6s 8ms/step - loss: 0.3981 - auc_4: 0.8671 - val_loss: 0.3800 - val_auc_4: 0.8958\n",
      "Epoch 6/10\n",
      "742/742 [==============================] - 6s 8ms/step - loss: 0.4012 - auc_4: 0.8661 - val_loss: 0.3653 - val_auc_4: 0.9073\n",
      "Epoch 7/10\n",
      "742/742 [==============================] - 6s 8ms/step - loss: 0.4107 - auc_4: 0.8609 - val_loss: 0.3605 - val_auc_4: 0.8859\n",
      "Epoch 8/10\n",
      "742/742 [==============================] - 6s 8ms/step - loss: 0.4009 - auc_4: 0.8650 - val_loss: 0.3713 - val_auc_4: 0.9218\n",
      "Epoch 9/10\n",
      "742/742 [==============================] - 6s 8ms/step - loss: 0.4090 - auc_4: 0.8633 - val_loss: 0.3603 - val_auc_4: 0.9322\n",
      "Epoch 10/10\n",
      "742/742 [==============================] - 6s 8ms/step - loss: 0.3895 - auc_4: 0.8893 - val_loss: 0.3746 - val_auc_4: 0.9507\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f5f510597f0>"
      ]
     },
     "execution_count": 300,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Input layer\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import datetime\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from keras.layers import Activation, Dense, Dropout\n",
    "from keras.layers import LeakyReLU\n",
    "import os\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(400,activation='relu', input_shape=(768,)))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(190, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(100))\n",
    "model.add(LeakyReLU(alpha=0.01))\n",
    "model.add(Dropout(0.7))\n",
    "model.add(Dense(60, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(30, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "\n",
    "optimizer =tf.keras.optimizers.Nadam(\n",
    "    learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, name='Nadam'\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy',metrics=[tf.keras.metrics.AUC()])\n",
    "\n",
    "model.fit(X_train_pooled_output,Y_train,epochs=10, validation_data=(X_test_pooled_output,Y_test), batch_size=16)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kcILeYZI9pxm"
   },
   "source": [
    "<Pre><font size=6>Part-6: Creating a Data pipeline for BERT Model</font> \n",
    "\n",
    "1. Download data from <a href=\"https://drive.google.com/file/d/1QwjqTsqTX2vdy7fTmeXjxP3dq8IAVLpo/view?usp=sharing\">here</a>\n",
    "2. Read the csv file\n",
    "3. Remove all the html tags\n",
    "4. Now do tokenization [Part 3 as mentioned above]\n",
    "    * Create tokens,mask array and segment array\n",
    "5. Get Embeddings from BERT Model [Part 4 as mentioned above] , let it be X_test\n",
    "   * Print the shape of output(X_test.shape).You should get (352,768)\n",
    "6. Predit the output of X_test with the Neural network model which we trained earlier.\n",
    "7. Print the occurences of class labels in the predicted output\n",
    "\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iiBeOnna9yDH"
   },
   "outputs": [],
   "source": [
    "data=pd.read_csv('/content/drive/MyDrive/NLP Transfer Learning/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3tlHOtiX5Z0F"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "7IM71DB6R3Eo",
    "outputId": "2be68cbc-580d-4994-a257-eb92ebb9e2bc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Just opened Greenies Joint Care (individually ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This product rocks :) My mom was very happy w/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The product was fine, but the cost of shipping...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I love this soup. It's great as part of a meal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Getting ready to order again. These are great ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text\n",
       "0  Just opened Greenies Joint Care (individually ...\n",
       "1  This product rocks :) My mom was very happy w/...\n",
       "2  The product was fine, but the cost of shipping...\n",
       "3  I love this soup. It's great as part of a meal...\n",
       "4  Getting ready to order again. These are great ..."
      ]
     },
     "execution_count": 302,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "41qgGOcH5uJ8",
    "outputId": "4e52408e-0757-4bbd-bb39-464f887feee8"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'These were delicious, but not wrapped as well as I think they should be.  They kind of melted out of their wrapping.'"
      ]
     },
     "execution_count": 324,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Text'][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1_MbNhl7SJvD"
   },
   "outputs": [],
   "source": [
    "#remove HTML from the Text column and save in the Text column only\n",
    "from bs4 import BeautifulSoup\n",
    "data['Text']=data['Text'].apply(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mSsh6rGdSRjV"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "q=[]\n",
    "X_test_tokens=[]\n",
    "y_test_=[]\n",
    "#X_train_mask=np.array([])\n",
    "for i in range(data.shape[0]):\n",
    "  try:\n",
    "    tokens=tokenizer.tokenize(data['Text'][i])\n",
    "  except:\n",
    "    continue\n",
    "  \n",
    "  tokens=tokens[:(max_seq_length-2)]\n",
    "  tokens=['[CLS]',*tokens,'[SEP]']\n",
    "  temp_length=len(tokens)\n",
    "  temp_X_train_tokens=tokenizer.convert_tokens_to_ids(tokens)\n",
    "  #print(temp_X_train_tokens)\n",
    "  X_test_tokens.append(temp_X_train_tokens)\n",
    "  temp_length=len(temp_X_train_tokens)\n",
    "  #print(tf.keras.preprocessing.sequence.pad_sequences(temp_X_train_tokens, maxlen=max_seq_length,padding='post'))\n",
    " # np.append(X_train_tokens,tf.keras.preprocessing.sequence.pad_sequences(temp_X_train_tokens, maxlen=max_seq_length,padding='post'),axis=0)\n",
    "  q.append(([1]*temp_length) + ([0]*(max_seq_length-temp_length)))\n",
    "  #X_train_mask=np.append(X_train_mask,np.array([1]*temp_length +[0]*(max_seq_length-temp_length)))\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iHAH-XAMSe9L",
    "outputId": "5d9e56a4-eab9-4866-a69c-d8fd7d68c2e3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(352, 55)"
      ]
     },
     "execution_count": 305,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_mask=np.array(q)\n",
    "X_test_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7g1ZA29PSl0T"
   },
   "outputs": [],
   "source": [
    "X_test_tokens=tf.keras.preprocessing.sequence.pad_sequences(X_test_tokens, maxlen=max_seq_length,padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2ABRRVNUStBu"
   },
   "outputs": [],
   "source": [
    "X_test_segment=np.zeros_like(X_test_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V0mZO5_bS0me"
   },
   "outputs": [],
   "source": [
    "# get the test output, BERT model will give one output so save in\n",
    "# X_test_pooled_output\n",
    "X_test_pooled_output=bert_model.predict([X_test_tokens,X_test_mask,X_test_segment])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s9D7QAkKS4Ei"
   },
   "outputs": [],
   "source": [
    "pred=model.predict_on_batch(X_test_pooled_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wAyi_hXOTBDk"
   },
   "outputs": [],
   "source": [
    "pred=tf.math.argmax(pred,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bc13SsSgTFjy",
    "outputId": "ae15771c-be3f-419c-fca0-62313d853726"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 318,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "TojZLB9l0crZ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook Copy_of_BERT_Assignment.ipynb to html\n",
      "[NbConvertApp] Writing 387150 bytes to Copy_of_BERT_Assignment.html\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to html Copy_of_BERT_Assignment.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of BERT- Assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
